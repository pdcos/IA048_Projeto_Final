{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import utils\n",
    "\n",
    "from torchaudio import datasets, transforms\n",
    "from torchvision import models\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.LIBRISPEECH(\n",
    "                            root=\"./\",\n",
    "                            url=\"dev-clean\",\n",
    "                            folder_in_archive=\"LibriSpeech\",\n",
    "                            download=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0024, 0.0021, 0.0020,  ..., 0.0004, 0.0006, 0.0010]]),\n",
       " 16000,\n",
       " 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL',\n",
       " 1272,\n",
       " 128104,\n",
       " 0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_lengths = []\n",
    "for value in dataset:\n",
    "    wav_lengths.append(value[0].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522320"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(wav_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = np.array(wav_lengths)\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 600000, 10000) # fixed bin size\n",
    "\n",
    "plt.xlim([min(data)-5, max(data)+5])\n",
    "\n",
    "plt.hist(data, bins=bins, alpha=0.5)\n",
    "plt.title('Random Gaussian data (fixed bin size)')\n",
    "plt.xlabel('variable X (bin size = 5)')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/deeplearning/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1).features\n",
    "decoder = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "transform = transforms.MelSpectrogram(16000, n_fft=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400000])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TokenizedDataset(utils.data.Dataset):\n",
    "    def __init__(self, raw_dataset, tokenizer, max_len=400000):\n",
    "        self.raw_dataset = raw_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.raw_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.raw_dataset[idx]\n",
    "        x = data[0]\n",
    "        y = data[2]\n",
    "\n",
    "        y = self.tokenizer.encode_plus(\n",
    "                                        text=y,  # the sentence to be encoded\n",
    "                                        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "                                        max_length=512,  # maximum length of a sentence\n",
    "                                        padding=\"max_length\",  # Add [PAD]s\n",
    "                                        return_tensors='pt',  # ask the function to return PyTorch tensors\n",
    "                                        truncation=True,\n",
    "                                    )\n",
    "\n",
    "        if x.shape[1] < self.max_len:\n",
    "            pad_x = torch.zeros((x.shape[0], self.max_len))\n",
    "            pad_x[:, :x.size(1)] = x\n",
    "            x = pad_x\n",
    "        else:\n",
    "            x = x[:,0:(self.max_len)]\n",
    "\n",
    "        \n",
    "        #return x,y[\"input_ids\"], y[\"attention_mask\"]\n",
    "        return x,y[\"input_ids\"].squeeze(), y[\"attention_mask\"].squeeze()\n",
    "\n",
    "mydataset = TokenizedDataset(dataset, tokenizer)\n",
    "mydataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = TokenizedDataset(dataset, tokenizer)\n",
    "\n",
    "train_set, val_set, test_set = utils.data.random_split(mydataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "#train_loader = utils.data.DataLoader(train_set, batch_size=2, num_workers=os.cpu_count())\n",
    "#val_loader = utils.data.DataLoader(val_set, batch_size=2, num_workers=os.cpu_count())\n",
    "#test_set = utils.data.DataLoader(test_set, batch_size=2, num_workers=os.cpu_count())\n",
    "\n",
    "train_loader = utils.data.DataLoader(train_set, batch_size=2)\n",
    "val_loader = utils.data.DataLoader(val_set, batch_size=2)\n",
    "test_set = utils.data.DataLoader(test_set, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder, transform, tokenizer):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        random_input = torch.rand((1,90000))\n",
    "        random_spectrogram = self.transform(random_input)\n",
    "        random_spectrogram = random_spectrogram.repeat(1,3,1,1)\n",
    "        random_extracted_features = self.encoder(random_spectrogram)\n",
    "        self.n_filters = random_extracted_features.shape[1]\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "\n",
    "        x = args[0]\n",
    "        out = self.transform(x)\n",
    "        out = out.repeat(1, 3, 1, 1)\n",
    "        out = self.encoder(out)\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        out = out.reshape(-1, int(out.shape[1] * out.shape[2] * out.shape[3]/ self.decoder.config.d_model), self.decoder.config.d_model )\n",
    "\n",
    "        if len(args) > 1:\n",
    "            y = args[1]\n",
    "            mask = args[2]\n",
    "            out = self.decoder(inputs_embeds=out, labels=y,return_dict=True, decoder_attention_mask=mask)\n",
    "        else:\n",
    "            out = self.decoder.generate(inputs_embeds=out,\n",
    "                                        max_length=1024,\n",
    "                                        min_length=0)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y, mask = train_batch\n",
    "        out  = self.forward(x, y, mask)\n",
    "        loss = out.loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_encoded_ids(encoded_ids_list, tokenizer):\n",
    "    phrases = []\n",
    "    for encoded_ids in encoded_ids_list:\n",
    "        decoded_ids = tokenizer.decode(encoded_ids, skip_special_tokens=True)\n",
    "        phrases.append(decoded_ids)\n",
    "    return phrases\n",
    "\n",
    "\n",
    "x = dataset[0][0]\n",
    "y = dataset[0][2]\n",
    "\n",
    "tz = tokenizer.encode_plus(\n",
    "    text=y,  # the sentence to be encoded\n",
    "    add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "    max_length=512,  # maximum length of a sentence\n",
    "    padding=\"max_length\",  # Add [PAD]s\n",
    "    return_tensors='pt',  # ask the function to return PyTorch tensors\n",
    "    truncation=True,\n",
    ")\n",
    "y = tz[\"input_ids\"]\n",
    "mask = tz[\"attention_mask\"]\n",
    "print(y.shape)\n",
    "\n",
    "model = EncoderDecoder(encoder=encoder,\n",
    "                       decoder=decoder,\n",
    "                       transform=transform,\n",
    "                       tokenizer=tokenizer)\n",
    "\n",
    "#model(x,y, mask).loss\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type                       | Params\n",
      "---------------------------------------------------------\n",
      "0 | encoder   | Sequential                 | 4.0 M \n",
      "1 | decoder   | T5ForConditionalGeneration | 60.5 M\n",
      "2 | transform | MelSpectrogram             | 0     \n",
      "---------------------------------------------------------\n",
      "64.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "64.5 M    Total params\n",
      "258.057   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc527e127c1440e992f7a0124fecfe87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = EncoderDecoder(encoder=encoder,\n",
    "                       decoder=decoder,\n",
    "                       transform=transform,\n",
    "                       tokenizer=tokenizer)\n",
    "trainer = pl.Trainer(gpus=0)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fed2aa9592218c4b4de25ecb09c6b292eb81f342cc059d9c96856c64676dbef4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
