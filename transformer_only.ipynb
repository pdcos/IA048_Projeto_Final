{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import utils\n",
    "\n",
    "from torchaudio import datasets, transforms\n",
    "from torchvision import models\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.LIBRISPEECH(\n",
    "                            root=\"./\",\n",
    "                            url=\"dev-clean\",\n",
    "                            folder_in_archive=\"LibriSpeech\",\n",
    "                            download=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: 104014\n",
      "Tamanho do conjunto de teste: 2620\n"
     ]
    }
   ],
   "source": [
    "dataset_train = datasets.LIBRISPEECH(\n",
    "                                     root=\"/mnt/f/train-clean-360\",\n",
    "                                     url=\"train-clean-360\",\n",
    "                                     folder_in_archive=\"LibriSpeech\",\n",
    "                                     download=False\n",
    "                                    )\n",
    "\n",
    "dataset_test = datasets.LIBRISPEECH(\n",
    "                                    root=\"/mnt/f/test-clean\",\n",
    "                                    url=\"test-clean\",\n",
    "                                    folder_in_archive=\"LibriSpeech\",\n",
    "                                    download=False\n",
    "                                    )\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(dataset_train)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0017,  0.0007, -0.0009,  ...,  0.0005,  0.0005,  0.0004]]),\n",
       " 16000,\n",
       " \"BUT HE WAS SO SLY AND CAUTIOUS THAT NO ONE HAD EVER CAUGHT HIM IN THE ACT OF STEALING ALTHOUGH A GOOD MANY THINGS HAD BEEN MISSED AFTER THEY HAD FALLEN INTO THE OLD MAN'S WAY BARNEY HAD ONE SON NAMED TOM\",\n",
       " 100,\n",
       " 121669,\n",
       " 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8767/1731720711.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwav_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mwav_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchaudio/datasets/librispeech.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mUtterance\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_waveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_archive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchaudio/datasets/librispeech.py\u001b[0m in \u001b[0;36mget_metadata\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[1;32m    144\u001b[0m         \u001b[0mfileid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_walker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_librispeech_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_archive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ext_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ext_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchaudio/datasets/librispeech.py\u001b[0m in \u001b[0;36m_get_librispeech_metadata\u001b[0;34m(fileid, root, folder, ext_audio, ext_txt)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mfile_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{speaker_id}-{chapter_id}{ext_txt}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mfile_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchapter_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mfileid_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/_bootlocale.py\u001b[0m in \u001b[0;36mgetpreferredencoding\u001b[0;34m(do_setlocale)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdo_setlocale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf8_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wav_lengths = []\n",
    "for value in tqdm(dataset_train):\n",
    "    wav_lengths.append(value[0].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31900"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wav_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475760"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(wav_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = np.array(wav_lengths)\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 600000, 10000) # fixed bin size\n",
    "\n",
    "plt.xlim([min(data)-5, max(data)+5])\n",
    "\n",
    "plt.hist(data, bins=bins, alpha=0.5)\n",
    "plt.title('Random Gaussian data (fixed bin size)')\n",
    "plt.xlabel('variable X (bin size = 5)')\n",
    "plt.ylabel('count')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1).features\n",
    "decoder = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "transform = transforms.MelSpectrogram(16000, n_fft=1252, n_mels=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TokenizedDataset(utils.data.Dataset):\n",
    "    def __init__(self, raw_dataset, tokenizer, max_len=320000):\n",
    "        self.raw_dataset = raw_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.raw_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.raw_dataset[idx]\n",
    "        x = data[0]\n",
    "        y = data[2]\n",
    "\n",
    "        y = self.tokenizer.encode_plus(\n",
    "                                        text=y,  # the sentence to be encoded\n",
    "                                        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "                                        max_length=512,  # maximum length of a sentence\n",
    "                                        padding=\"max_length\",  # Add [PAD]s\n",
    "                                        return_tensors='pt',  # ask the function to return PyTorch tensors\n",
    "                                        truncation=True,\n",
    "                                    )\n",
    "\n",
    "        if x.shape[1] < self.max_len:\n",
    "            pad_x = torch.zeros((x.shape[0], self.max_len))\n",
    "            pad_x[:, :x.size(1)] = x\n",
    "            x = pad_x\n",
    "        else:\n",
    "            x = x[:,0:(self.max_len)]\n",
    "\n",
    "        \n",
    "        #return x,y[\"input_ids\"], y[\"attention_mask\"]\n",
    "        return x,y[\"input_ids\"].squeeze(), y[\"attention_mask\"].squeeze()\n",
    "\n",
    "mydataset = TokenizedDataset(dataset, tokenizer)\n",
    "mydataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = TokenizedDataset(dataset, tokenizer)\n",
    "\n",
    "train_set, val_set, test_set = utils.data.random_split(mydataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "train_loader = utils.data.DataLoader(train_set, batch_size=4, num_workers=os.cpu_count())\n",
    "val_loader = utils.data.DataLoader(val_set, batch_size=4, num_workers=os.cpu_count())\n",
    "test_set = utils.data.DataLoader(test_set, batch_size=4, num_workers=os.cpu_count())\n",
    "\n",
    "#train_loader = utils.data.DataLoader(train_set, batch_size=2)\n",
    "#val_loader = utils.data.DataLoader(val_set, batch_size=2)\n",
    "#test_set = utils.data.DataLoader(test_set, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset_train = TokenizedDataset(dataset_train, tokenizer)\n",
    "mydataset_test = TokenizedDataset(dataset_test, tokenizer)\n",
    "\n",
    "\n",
    "train_set, val_set = utils.data.random_split(mydataset_train, [0.99, 0.01], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = utils.data.DataLoader(train_set, batch_size=10, shuffle=True, num_workers=os.cpu_count())\n",
    "val_loader = utils.data.DataLoader(val_set, batch_size=10, num_workers=os.cpu_count())\n",
    "test_loader = utils.data.DataLoader(mydataset_test, batch_size=10, num_workers=os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.MelSpectrogram(16000, n_fft=1252, n_mels=128)\n",
    "\n",
    "class EncoderDecoder(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder, transform, tokenizer):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        random_input = torch.rand((1,90000))\n",
    "        random_spectrogram = self.transform(random_input)\n",
    "        random_spectrogram = random_spectrogram.repeat(1,3,1,1)\n",
    "        random_extracted_features = self.encoder(random_spectrogram)\n",
    "        self.n_filters = random_extracted_features.shape[1]\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "\n",
    "        x = args[0]\n",
    "        out = self.transform(x)\n",
    "        out = out.squeeze()\n",
    "\n",
    "        if len(args) > 1:\n",
    "            y = args[1]\n",
    "            out = self.decoder(inputs_embeds=out, labels=y, decoder_input_ids=None ,return_dict=True)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def generate(self, \n",
    "                 x,\n",
    "                 max_length=1024,\n",
    "                 min_length=0,\n",
    "                 num_beams=5,\n",
    "                 no_repeat_ngram_size=2,\n",
    "                 num_return_sequences=1,\n",
    "                 early_stopping=True,\n",
    "                 decode=False):\n",
    "\n",
    "        out = self.forward(x)\n",
    "        #encoder_outputs  = self.decoder.encoder(inputs_embeds=out)\n",
    "        #out = self.decoder.generate(encoder_outputs = encoder_outputs, max_length = max_length, min_length=min_length)\n",
    "        out = self.decoder.generate(inputs_embeds=out,\n",
    "                                    max_length=max_length,\n",
    "                                    min_length=min_length,\n",
    "                                    num_beams=num_beams,\n",
    "                                    no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                    num_return_sequences=num_return_sequences,\n",
    "                                    early_stopping=early_stopping)\n",
    "\n",
    "        \n",
    "        if decode:\n",
    "            out = self.translate_encoded_ids(out)\n",
    "\n",
    "        return out \n",
    "\n",
    "    def translate_encoded_ids(self, encoded_ids_list):\n",
    "        phrases = []\n",
    "        for encoded_ids in encoded_ids_list:\n",
    "            decoded_ids = self.tokenizer.decode(encoded_ids, skip_special_tokens=True)\n",
    "            phrases.append(decoded_ids)\n",
    "        return phrases\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y, mask = train_batch\n",
    "        out  = self.forward(x, y)\n",
    "        loss = out.loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx, log=True):\n",
    "        x, y, mask = val_batch\n",
    "        decoded_y = self.translate_encoded_ids(y)\n",
    "        \n",
    "        gen_pred = self.generate(x)\n",
    "        decoded_gen_pred = self.translate_encoded_ids(gen_pred)\n",
    "\n",
    "        scores = []\n",
    "        for string_comb in zip(decoded_y, decoded_gen_pred):\n",
    "            score = self.levensthein_distance(string_comb[0], string_comb[1])\n",
    "            scores.append(score)\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        batch_score = scores.mean()\n",
    "\n",
    "        if log:\n",
    "            self.log(\"val_levensthein\", batch_score)\n",
    "\n",
    "        return batch_score\n",
    "\n",
    "    def test_step(self, test_batch, test_idx):\n",
    "        test_score = self.validation_step(test_batch, test_idx, log=False)\n",
    "        self.log(\"test_levensthein\", test_score )\n",
    "        return test_score\n",
    "\n",
    "    def levensthein_distance(self, str_1, str_2):\n",
    "        str_1 = str_1.upper()\n",
    "        str_2 = str_2.upper()\n",
    "        str_1 = str_1.translate(str.maketrans('','', string.punctuation))\n",
    "        str_2 = str_2.translate(str.maketrans('','', string.punctuation))\n",
    "        dist = (1 - nltk.edit_distance(str_2, str_1)/max(len(str_1), len(str_2)))\n",
    "        return dist\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "#model = EncoderDecoder(encoder=encoder,\n",
    "#                       decoder=decoder,\n",
    "#                       transform=transform,\n",
    "#                       tokenizer=tokenizer)\n",
    "\n",
    "#batch_x, batch_y, mask = next(iter(train_loader))\n",
    "\n",
    "#gen_phrase = model.generate(batch_x, mask, decode=True)\n",
    "#model.forward(batch_x, batch_y).logits.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_671/1048422753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgen_phrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_671/1975582979.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, max_length, min_length, num_beams, no_repeat_ngram_size, num_return_sequences, early_stopping, decode)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#encoder_outputs  = self.decoder.encoder(inputs_embeds=out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#out = self.decoder.generate(encoder_outputs = encoder_outputs, max_length = max_length, min_length=min_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         out = self.decoder.generate(inputs_embeds=out,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                     \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                     \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             )\n\u001b[1;32m   1576\u001b[0m             \u001b[0;31m# 12. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1578\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2818\u001b[0m             )\n\u001b[1;32m   2819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2820\u001b[0;31m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reorder_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_in_generate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36m_reorder_cache\u001b[0;34m(self, past, beam_idx)\u001b[0m\n\u001b[1;32m   1744\u001b[0m                 \u001b[0;31m# need to set correct `past` for each of the four key / value states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 reordered_layer_past_states = reordered_layer_past_states + (\n\u001b[0;32m-> 1746\u001b[0;31m                     \u001b[0mlayer_past_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_past_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1747\u001b[0m                 )\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = EncoderDecoder(encoder=encoder,\n",
    "                       decoder=decoder,\n",
    "                       transform=transform,\n",
    "                       tokenizer=tokenizer)\n",
    "\n",
    "batch_x, batch_y, mask = next(iter(train_loader))\n",
    "\n",
    "gen_phrase = model.generate(batch_x, decode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoder(encoder=encoder,\n",
    "                       decoder=decoder,\n",
    "                       transform=transform,\n",
    "                       tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"neptune_key.txt\", \"r\") as f:\n",
    "    neptune_api_key = f.read()\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=neptune_api_key,  # replace with your own\n",
    "    project=\"p175857/IA048\",  # format \"<WORKSPACE/PROJECT>\"\n",
    "    tags=[\"prod\", \"transformeronly\"],  # optional\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"/mnt/f/IA048/BestModels/TransformerOnly/\", save_top_k=1, save_last=True, every_n_epochs=1, monitor=\"val_levensthein\", mode=\"max\", save_on_train_epoch_end=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dev/.local/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ encoder   │ Sequential                 │ 10.7 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ decoder   │ T5ForConditionalGeneration │ 60.5 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ transform │ MelSpectrogram             │      0 │\n",
       "└───┴───────────┴────────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ encoder   │ Sequential                 │ 10.7 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ decoder   │ T5ForConditionalGeneration │ 60.5 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ transform │ MelSpectrogram             │      0 │\n",
       "└───┴───────────┴────────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 71.2 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 71.2 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 284                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 71.2 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 71.2 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 284                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943d6e95fe684cfc82108d52d79b9491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">https://app.neptune.ai/p175857/IA048/e/IA-14\n",
       "</pre>\n"
      ],
      "text/plain": [
       "https://app.neptune.ai/p175857/IA048/e/IA-14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It \n",
       "will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It \n",
       "will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/dev/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected \n",
       "KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/dev/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected \n",
       "KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1, callbacks=[RichProgressBar(), checkpoint_callback], logger=neptune_logger)\n",
    "#trainer.fit(model, train_loader, val_loader, ckpt_path=\".neptune/None/version_None/checkpoints/epoch=4-step=4055.ckpt\")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/mnt/f/IA048/BestModels/TransformerOnly/last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF A MAN HAD STOLEN A POUND IN HIS YOUTH AND HAD USED THAT POUND TO AMASS A HUGE FORTUNE HOW MUCH WAS HE OBLIGED TO GIVE BACK THE POUND HE HAD STOLEN ONLY OR THE POUND TOGETHER WITH THE COMPOUND INTEREST ACCRUING UPON IT OR ALL HIS HUGE FORTUNE\n",
      "torch.Size([1, 268640])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_283/393466954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_283/3127857582.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, max_length, min_length, num_beams, no_repeat_ngram_size, num_return_sequences, early_stopping, decode)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#encoder_outputs  = self.decoder.encoder(inputs_embeds=out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#out = self.decoder.generate(encoder_outputs = encoder_outputs, max_length = max_length, min_length=min_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         out = self.decoder.generate(inputs_embeds=out,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                     \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                     \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   1340\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;31m# required mask seq length can be calculated via length of past\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "x = dataset_test[20][0]\n",
    "y = dataset_test[20][2]\n",
    "print(y)\n",
    "print(x.shape)\n",
    "y = tokenizer.encode_plus(\n",
    "                                text=y,  # the sentence to be encoded\n",
    "                                add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "                                max_length=512,  # maximum length of a sentence\n",
    "                                padding=\"max_length\",  # Add [PAD]s\n",
    "                                return_tensors='pt',  # ask the function to return PyTorch tensors\n",
    "                                truncation=True,\n",
    "                            )\n",
    "\n",
    "\n",
    "model.generate(x, decode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y, mask = next(iter(test_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AFTER THE MANNER OF ONE OF THEM HE BEGAN TO PUT AN END TO HIS CHARACTER BUT THERE WAS NOTHING ELSE TO BE DONE YET THEY WERE GOING TO TAKE THEIR PLACE IN A FEW MINUTES THE SOLDIERS REMAINED SILENT AND STOOD READY TO LOOK AT HIM AND LAY DOWN AGAIN ON THE GROUND',\n",
       " 'SHE SAW THAT HE HAD BEEN TRYING TO GET OUT OF THE KITCHEN WHICH WAS ABOUT TO TAKE HIM OFF AND THEN THEY SAT DOWN TOGETHER AND LOOKED AT EACH OTHER WITH AN EXPRESSION OF INDIGNATION I AM GLAD TO SEE YOU YESTERDAY I SHALL NOT BE ABLE TO SAY ANYTHING',\n",
       " 'FOR ALTHOUGH THEY WERE CHANGED INTO ONE ANOTHER AND AFTER A FEW MINUTES HAD BEGUN TO TALK ABOUT THE SAME THING WHICH WAS TO BE DONE',\n",
       " 'ASKED THE MAN IF THERE WAS SOMETHING ABOUT HIM WHILE THE DOOR OPENED AND THEN HE TURNED IN AND LOOKED AFTER THEM AS THOUGH THEY HAD BEEN SEARCHING FOR THEIR NEIGHBOURS NOR DID ANY ONE ELSE THINK THAT THE MOST DISAGREEABLE CREATURE EVER SAW',\n",
       " \"SEEING THAT HE HAD BEEN TALKING TO HIMSELF IN AN ENGLISHMAN'S HOUSE ON THE OTHER SIDE OF THE STAIRCASE THERE WAS SOMETHING IN HIS VOICE WHICH LOOKED AS THOUGH THEY WERE GOING TO DO IT\",\n",
       " 'AND SOMETIMES PASSED THROUGH THE STREETS TO THE SOUTH WHERE THEY HAD BEEN SITTING AND LOOKED ABOUT FOR A FEW MINUTES BEFORE THE TWO MEN WERE SEATED ON THE GROUND WHICH STOOD AT THE BACK OF THE STAIRCASE THERE WAS SOMETHING TO BE SEEN FROM THE SHUTTERS OF AN OLD WOMAN STANDING ON HIS HEAD',\n",
       " \"THAT'S THE WORD I'VE GOT TO SAY ABOUT THE MATTER AND I CAN'T GET OUT OF IT IF YOU'RE GOING TO SEE ME\",\n",
       " 'IN THE VERY MIDDLE OF THE MORNING HE WAS SITTING UP WITH HIS OWN HANDS WHICH SHONE LIKE A SHADOWY SUNSHINE AND THEN SHE THOUGHT OF HERSELF BEFORE HIM AND WHEN THEY HAD FINISHED TALKING ABOUT IT ALL DAY LONG',\n",
       " 'AS SOON AS HE REMEMBERED THERE WAS NO DOUBT BUT THAT THEY WERE IN THE HABIT OF COMING TOGETHER AND THEN TURNED THEIR HEADS TOWARDS HIM VERY CAREFULLY BUT EVEN NOW',\n",
       " 'I THINK THERE IS NO REASON WHY I SHOULD HAVE BEEN SO ANXIOUS TO GET OUT OF MY WAY IF THEY WERE TO TAKE THEIR PLACE IN THE MIDDLE OF THE SUMMER EVENING']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_phrase = model.generate(batch_x, decode=True)\n",
    "\n",
    "gen_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I THINK THERE CAN BE NOTHING MORE FLAT AND DISAGREEABLE I PREFER TASSO A GOOD DEAL OR EVEN THE SOPORIFIC TALES OF ARIOSTO'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch_y[9],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load(\"lightning_logs/version_4/checkpoints/epoch=0-step=811.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at /mnt/f/IA048/BestModels/TransformerOnly/epoch=1-step=20596.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /mnt/f/IA048/BestModels/TransformerOnly/epoch=1-step=20596.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce82820b6d064973b68b367d4cd4d7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_levensthein      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2522143157814199     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_levensthein     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2522143157814199    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_levensthein': 0.2522143157814199}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices=1, callbacks=[RichProgressBar()])\n",
    "trainer.test(model, test_loader, ckpt_path='/mnt/f/IA048/BestModels/TransformerOnly/epoch=1-step=20596.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at /mnt/f/IA048/BestModels/TransformerOnly/last.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /mnt/f/IA048/BestModels/TransformerOnly/last.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ec724850ea4124bba1ba7d3b768a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_174/1587030853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRichProgressBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/mnt/f/IA048/BestModels/TransformerOnly/last.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`Trainer.test()` requires a `LightningModule`, got: {model.__class__.__qualname__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         return call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    758\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;31m# run test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         ):\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0meval_loop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;31m# remove the tensors from the eval results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataloader_idx\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mdl_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# store batch level output per dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[1;32m    233\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_174/1975582979.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, test_batch, test_idx)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_levensthein\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_174/1975582979.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, val_batch, batch_idx, log)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdecoded_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_encoded_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mgen_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mdecoded_gen_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_encoded_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_174/1975582979.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, max_length, min_length, num_beams, no_repeat_ngram_size, num_return_sequences, early_stopping, decode)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#encoder_outputs  = self.decoder.encoder(inputs_embeds=out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#out = self.decoder.generate(encoder_outputs = encoder_outputs, max_length = max_length, min_length=min_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         out = self.decoder.generate(inputs_embeds=out,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                     \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                     \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             )\n\u001b[1;32m   1576\u001b[0m             \u001b[0;31m# 12. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1578\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2745\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2747\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2748\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 )\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1041\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    674\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    577\u001b[0m     ):\n\u001b[1;32m    578\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_value_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         )\n\u001b[0;32m--> 504\u001b[0;31m         value_states = project(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_value_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0;31m# self-attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                     \u001b[0;31m# (batch_size, n_heads, key_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                     \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                     \u001b[0;31m# cross-attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices=1, callbacks=[RichProgressBar()])\n",
    "trainer.test(model, test_loader, ckpt_path='/mnt/f/IA048/BestModels/TransformerOnly/last.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/mnt/f/IA048/BestModels/TransformerOnly/last.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/mnt/f/IA048/BestModels/TransformerOnly/epoch=1-step=20596.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y, mask = next(iter(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE OLD WOMAN WAS SEATED ON THE TABLE BESIDE HER AND SAT DOWN BY THE SIDE OF THE WINDOW WHILE HE STOOD THERE TALKING ABOUT SOMETHING ELSE BUT SAID NOTHING',\n",
       " 'SUPPOSE HE HAD BEEN EXPECTING TO GET OUT OF THE HOUSE',\n",
       " 'AND THOUGH THERE WERE MANY OTHER ANIMALS IN THE UNITED STATES THEY HAD VERY LITTLE TO SAY TO THEMSELVES',\n",
       " 'WHAT ARE THEY GOING TO DO ABOUT IT',\n",
       " \"NOT VERY EXTRAVAGANT BUT YET I CAN'T HELP THINKING ABOUT THE MATTER SAID THE PROFESSOR\",\n",
       " 'THEN HE IMMEDIATELY REMEMBERED THAT THERE WERE OTHER THINGS WHICH WOULD NOT HAVE BEEN SUFFICIENT TO SURPRISE HIM AND THAT SHE WAS NOT THE ONLY MAN IN THE WORLD WHO HAD EVER SEEN',\n",
       " 'THE LETTER ALLOWED AFTERWARDS TO TAKE PLACE BETWEEN HIM AND MANY OTHERS WHICH HE HAD BROUGHT TO HIS MIND THE SAME REASON THAT THEY WERE SOMEWHAT SURPRISED AT THEIR APPEARANCE',\n",
       " 'ACCORDINGLY HE WAS DRIVEN BACK TO THE RIVER AND SAID TO HIMSELF',\n",
       " 'THE CABIN WAS SHOWN TO BE ONE OF THE MOST IMPORTANT THINGS IN THE WORLD THAT HE HAD EVER SEEN BEFORE',\n",
       " 'I CALLED TO MY CHILDREN ALL THE SAME THINGS THAT WERE DISCOVERED IN THE EARLY DAYS OF THEIR MARRIED LIFE BUT I COULD NOT SPEAK TO EACH OTHER AS HE SPOKE']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_phrase = model.generate(batch_x.to('cuda'), decode=True)\n",
    "\n",
    "gen_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HE HOPED THERE WOULD BE STEW FOR DINNER TURNIPS AND CARROTS AND BRUISED POTATOES AND FAT MUTTON PIECES TO BE LADLED OUT IN THICK PEPPERED FLOUR FATTENED SAUCE',\n",
       " 'STUFF IT INTO YOU HIS BELLY COUNSELLED HIM',\n",
       " 'AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS',\n",
       " 'HELLO BERTIE ANY GOOD IN YOUR MIND',\n",
       " 'NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD NIGHT HUSBAND',\n",
       " \"THE MUSIC CAME NEARER AND HE RECALLED THE WORDS THE WORDS OF SHELLEY'S FRAGMENT UPON THE MOON WANDERING COMPANIONLESS PALE FOR WEARINESS\",\n",
       " 'THE DULL LIGHT FELL MORE FAINTLY UPON THE PAGE WHEREON ANOTHER EQUATION BEGAN TO UNFOLD ITSELF SLOWLY AND TO SPREAD ABROAD ITS WIDENING TAIL',\n",
       " 'A COLD LUCID INDIFFERENCE REIGNED IN HIS SOUL',\n",
       " 'THE CHAOS IN WHICH HIS ARDOUR EXTINGUISHED ITSELF WAS A COLD INDIFFERENT KNOWLEDGE OF HIMSELF',\n",
       " 'AT MOST BY AN ALMS GIVEN TO A BEGGAR WHOSE BLESSING HE FLED FROM HE MIGHT HOPE WEARILY TO WIN FOR HIMSELF SOME MEASURE OF ACTUAL GRACE']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate_encoded_ids(encoded_ids_list):\n",
    "    phrases = []\n",
    "    for encoded_ids in encoded_ids_list:\n",
    "        decoded_ids = tokenizer.decode(encoded_ids, skip_special_tokens=True)\n",
    "        phrases.append(decoded_ids)\n",
    "    return phrases\n",
    "\n",
    "translate_encoded_ids(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HE WAS VERY GLAD TO SEE HIMSELF IN THE MIDDLE OF HIS EYES AND LOOKED UPON HER HEAD AND SHE TURNED AWAY TO THE FLOOR WHICH AFTERWARDS HAD BEEN DISCOVERED',\n",
       " 'WHICH HE HAD BEEN DISCOVERED BY HIS FRIENDSHIP',\n",
       " 'WHICH HE HAD BEEN DISAPPOINTED BY HIS FRIENDSHIP AND THERE WAS A FEW DAYS AFTERWARDS IN THE MIDDLE OF THE TWO ROOMS',\n",
       " 'WHICH HE HAD BEEN DISCOVERED BY HIMSELF',\n",
       " 'WHICH HE HAD BEEN DISAPPOINTED BY HIS FRIENDSHIP AND THOUGHT OF HIMSELF THAT THERE WAS NOTHING IN THE WORLD',\n",
       " 'WHICH HE HAD BEEN DISCOVERED BY HIS FRIENDSHIP AND THOUGHT OF HIMSELF THAT THERE WAS NOTHING IN THE WORLD ABOUT IT BUT IF THEY WERE NOT ABLE TO GET OUT OF THEIR HANDS',\n",
       " 'HE WAS VERY GLAD TO SEE HIMSELF IN THE MIDDLE OF HIS EYES AND LOOKED UPON HER AND SHE HAD BROUGHT OUT A FEW MINUTES AGO AND THEN TURNED DOWN TO THE DOOR',\n",
       " 'HE THOUGHT IT WAS AN OLD WOMAN WHO HAD BEEN IN THE HOUSE OF HIMSELF',\n",
       " 'HE WAS GOING TO SEE HIMSELF UPON HIS FACE AND THOUGHT THAT THEY WERE VERY GLAD TO GET OUT OF THE HOUSE',\n",
       " 'HE THOUGHT THAT THERE WAS AN EXPERIENCE IN THE MIDDLE OF HIS EYES WHICH HAD BEEN SUFFICIENTLY DISCOVERED BY HIMSELF AND THEY WERE VERY IMPORTANT TO LOOK UPON THEM ABOUT ONE DAY AND AFTER A FEW YEARS']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_phrase = model.generate(batch_x.to('cuda'), decode=True)\n",
    "\n",
    "gen_phrase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d01aede67af52a000e9299dba81bb1cadce6b5511ce195c73da7e76597aeed4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
